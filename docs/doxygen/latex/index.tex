\chapter{A scalable interface between data and analysis underneath R}
\hypertarget{index}{}\label{index}\index{A scalable interface between data and analysis underneath R@{A scalable interface between data and analysis underneath R}}
  Reading genomic data files (\href{https://www.ebi.ac.uk/training/online/courses/human-genetic-variation-introduction/variant-identification-and-analysis/understanding-vcf-format/}{\texttt{ VCF}}, \href{https://samtools.github.io/bcftools/howtos/index.html}{\texttt{ BCF}}, \href{https://www.chg.ox.ac.uk/~gav/bgen_format/index.html}{\texttt{ BGEN}}, \href{https://anndata.readthedocs.io/en/latest/index.html}{\texttt{ H5\+AD}}, \href{https://bioconductor.org/packages/DelayedArray}{\texttt{ Delayed\+Array}}) into R/\+Rcpp in chunks for analysis with \href{https://doi.org/10.21105/joss.00026}{\texttt{ Armadillo}} / \href{eigen.tuxfamily.org}{\texttt{ Eigen}} / \href{https://www.rcpp.org}{\texttt{ Rcpp}} libraries. Mondern datasets are often too big to fit into memory, and many analyses operate a small chunk features at a time. Yet in practice, many implementations require the whole dataset stored in memory. Others pair an analysis with a specific data format (i.\+e. regresson analysis paired genotype data from a VCF) in way that the two components can\textquotesingle{}t be separated for use in other applications.  The {\ttfamily Genomic\+Data\+Stream} C++ inferface separates

1) data source 2) streaming chunks of features into a data matrix 3) downstream analysis ~\newline
 